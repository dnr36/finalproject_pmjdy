---
title: "Data Science for Public Policy"
subtitle: "Final Project: Predicting the PMJDY Takeup Rate in India"
author: "Meenakshi Alagusundaram - ma2309, Sanya Bahal - sb2063, Diana Rivas - dnr36, Sona Sarin - srs368"
execute:
  warning: false
format:
  html:
    embed-resources: true
---

# Loading Libraries

```{r Libraries }
library(tidyverse)
library(haven)
library(dplyr)
library(ggplot2)
library(tidymodels)
library(readr)  
library(ranger)
library(sf)
library(rgeoboundaries)
library(ggthemes)
```

# Set Up

### Preparing data

```{r Prepping data }

pmjdy <- read_dta("PMJDYmaster.dta") %>%
  filter(!year == 2021) 


# Changing all variable names to lower case
names(pmjdy) <- tolower(names(pmjdy))

# Making a SF to conduct geospatial analysis 
sf_pmjdy <- st_as_sf(pmjdy, coords = c("longitude", "latitude")) %>%
  st_set_crs(4326)

#editing latitude and longitude data 
pmjdy <- pmjdy %>%
  mutate(
    Latitude = case_when(
      Latitude == 18.9 ~ 19.8,
      Latitude == 17.5 ~ 15.9,
      TRUE ~ Latitude  # Keeps original value if conditions are not met
    ),
    Longitude = case_when(
      Longitude == 72.8 ~ 75.7,  # Note: Your condition said 'if Latitude==72.8', assuming typo, corrected it to Longitude
      Longitude == 78.6 ~ 79.7,
      TRUE ~ Longitude  # Keeps original value if conditions are not met
    )
  )

```

# Geospatial Analysis

```{r}
# Loading data for the map of India 
india <- geoboundaries(
  country = "India",
  adm_lvl = "adm1",
  type = "simplified"
  )

# Some of the names contain special characters not found in the main PMJDY data set 
india <- india %>%
  mutate(shapeName = case_when(
    shapeName == "Mah훮r훮shtra" ~ "Maharashtra", 
    shapeName == "N훮g훮land" ~ "Nagaland",
    TRUE ~ shapeName
  ))

# Displaying map of India
ggplot(data = india) +
  geom_sf()

# Setting crs as the same from sf_pmjdy to ensure spatial join is done correctly 
india <- st_transform(india, crs = st_crs(sf_pmjdy))

# Spatial join 
india_pmjdy <- st_join(india, sf_pmjdy)

# Creating a choropleth 

india_pmjdy %>%
    ggplot() +
    geom_sf(aes(fill = educationindex), color = "darkorange3", size = 0.1) +
    scale_fill_gradient(
        low = "white", 
        high = "darkgreen",
    ) +
    theme_void()

```

# Supervised Machine Learning Models 

### Set Up for Models and EDA through data visualization

```{r Supervised ML and EDA }

# Employment vs Literacy for state Delhi 
# Splitting data into training and testing data 
set.seed(2588596)

pmjdy_split <- initial_split(data = pmjdy, prop = 0.8)

# Creating the training and testing data
df_train <- training(x = pmjdy_split)
df_test  <- testing(x = pmjdy_split)

# Cross validation folds, tried to stratify by state but the data is too small 
folds <- vfold_cv(df_train, v=10)


delhi_data <- df_train[df_train$state == "Delhi", ]

# Create the plot
eda1 <- ggplot(delhi_data, aes(x = educationindex, y = employment)) +
  geom_point() +  # Adds the dot plot
  geom_smooth(method = "lm", se = FALSE, color = "blue") +  
  labs(x = "Literacy Rate", y = "Employment Rate", title = "Employment vs Literacy in Delhi") +
  theme_minimal()  

# employment vs literacy for all states for the year 2019 

data_2019 <- df_train[df_train$year == 2019, ]

# Create the plot for all states
eda2 <- ggplot(data_2019, aes(x = educationindex, y = employment, color = state)) +
  geom_point() +  
  geom_smooth(method = "lm", se = FALSE, color = "black") +  
  labs(x = "Literacy Rate", y = "Employment Rate", title = "Employment vs Literacy Across States for 2019") +
  theme_minimal() +  # Uses a minimal theme for the plot
  theme(legend.position = "bottom") 

# pmjdy beneficiary rate over 2016 - 2020 
# Calculating the mean of 'pmjdy' for each year
annual_means <- df_train %>%
  group_by(year) %>%
  summarize(mean_pmjdy = mean(pmjdy, na.rm = TRUE))  

# Plotting the annual mean of 'pmjdy'
eda3 <- ggplot(annual_means, aes(x = year, y = mean_pmjdy)) +
  geom_line(color = "blue", size = 1) +  # Adds a blue line connecting the mean values
  geom_point(color = "red", size = 3) +  # Adds red points for each yearly mean
  labs(x = "Year", y = "PMJDY", title = "Beneficiary rate of PMJDY from 2016 to 2020") +
  theme_minimal() +
  theme(legend.position = "none")  # No need for a legend  

eda1

eda2

eda3

```



# Models

```{r Recipe }

# Creating a recipe 

pmjdy_rec <- recipe(pmjdy ~ state + year + incomeindex + educationindex, df_train)%>%
  step_dummy(state) %>%
  step_normalize(all_numeric(), -all_outcomes())


```

### Decision tree model

```{r Decision tree model }

# Decision tree specification 
dt_spec <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("regression")

# Decision tree workflow 
dt_wf <- workflow() %>%
  add_recipe(pmjdy_rec) %>%
  add_model(dt_spec)

# Fitting decision tree
dt_fit_rs <- dt_wf %>%
  fit_resamples(resamples = folds,
                control = control_resamples(save_pred = TRUE),
                metrics = metric_set(rmse, mae,rsq))

# Decision tree metrics
dt_metrics <- collect_metrics(dt_fit_rs, summarize = FALSE)


# Caculating mean rsme
tree_mean_rmse <- dt_metrics %>%
  filter(.metric == "rmse") %>%
  pull(.estimate) %>%
  mean()

```

### Lasso model with hyper parameter tuning

```{r Lasso model }
# Lasso specification

lasso_mod <- linear_reg(penalty = tune(), mixture = tune()) %>%
    set_engine("glmnet") %>%
  set_mode("regression")

# Workflow and tuning grid 

lasso_mod_wf <- workflow() %>%
    add_model(spec = lasso_mod) %>%
    add_recipe(recipe = pmjdy_rec)
    
    # creating tuning grid 
    grid <- grid_regular(penalty(), mixture(), levels = 10)

# Fitting model 
    
lasso_fit_rs <- lasso_mod_wf %>%
    tune_grid(resamples = folds, 
              grid = grid, 
              control = control_grid(save_pred = TRUE),
              metrics = metric_set(rmse))   

# Calculating metrics 

lasso_metrics <- lasso_fit_rs %>%
    collect_metrics(summarize = FALSE)

# Calculating mean RMSE for Lasso

lasso_mean_rmse <- lasso_metrics %>%
  filter(.metric == "rmse") %>%
  pull(.estimate) %>%
  mean()

```

### Random forest model

```{r Random forest model }
# Define the model specification
rf_spec <- rand_forest(trees = 1000) %>%
  set_mode("regression") %>%
  set_engine("ranger")

# Set up the workflow
rf_wf <- workflow() %>%
  add_recipe(pmjdy_rec) %>%
  add_model(rf_spec)

# Fitting model 
rf_fit_rs <- rf_wf %>%
    fit_resamples(resamples = folds)

# Calculating metrics 
rf_metrics <- rf_fit_rs %>%
    collect_metrics(summarize = FALSE)

# Mean rmse 
rf_mean_rmse <- rf_metrics %>%
  filter(.metric == "rmse") %>%
  pull(.estimate) %>%
  mean()

```

### Visualizing the models

```{r Visualizing the models }

# Visualizing all models

ggplot() +
geom_point(data = lasso_metrics %>% filter(.metric == "rmse"), aes(x= id, y =.estimate, color = "Lasso")) +
geom_point(data = dt_metrics %>% filter(.metric == "rmse"), aes(x= id, y =.estimate, color = "Tree")) +
geom_point(data = rf_metrics %>% filter(.metric == "rmse"), aes(x= id, y =.estimate, color = "KNN")) +
labs( title = "RMSE by model and by fold", color = "Model", x = "Fold", y = "Estimate" )


```

# Estimation

```{r Estimations }
# Selecting best models, however from the calculation of the mean RMSE above, we know that lasso leads to the lowest root mean square error 

best_lasso <- lasso_fit_rs %>%
  select_best(metric = "rmse") 

final_lasso <- finalize_workflow(
  lasso_mod_wf,
  best_lasso) %>%
    fit(data = df_train)

# Making predictions on the testing data
predictions <- 
    bind_cols(
        df_test, 
        predict(object = final_lasso, new_data = df_test)
    )

# Printing results
predictions %>%
  select(pmjdy, .pred) %>%
  print()

# Evaluating model 
 predictions %>%
  metrics(truth = pmjdy, estimate = .pred)
```

# Interpretation

This model has a high R squared with somewhat low RMSE compared to the other models. This means it can be an adequate model to predict the take up of the PMJDY program. We can see that the predictions are a few percentage points off, so although the prediction is approximately accurate, it is important to note that the predictions are not very precise.

For the context of this program, this model can be used to predict the take up of the program in a certain place. The model would be a helpful tool because it can approximately predict if there will be a high enough take up rate that will make the investment/government expenditure worth it.\
\
To make our models more efficient, we would make use od feature engineering techniques like data imputation that helps us deal with missing values and normalizing or standardizing numerical features to ensure they have a similar scale.

Models that we can try next to improve upon our results are KNN and CART models. If there are clear clusters or patterns in the feature space that could be captured by the nearest neighbors, KNN may perform well. Decision trees like CART can capture non-linear relationships between features and the target variable, making them suitable for data sets with complex decision boundaries.
